---
layout: post
title: "The Meteoric Rise [and the Fall] of $NVDA"
author: "Suresh L. Paul"
categories: posts
tags: [posts, technology, finance, economics, stock analysis, gdp, USA, China, Nvidia, artificial intelligence, LLMs]
image: nana-dua-aVeKubCF-48-unsplash.jpg
---

<p align="center">
  <br>
  <em>Photo by Nana Dua on <a href="https://unsplash.com/photos/black-and-silver-round-device-aVeKubCF-48">Unsplash</a></em>
</p>

Nvidia (Ticker: $NVDA) supplies the lion's share of high resource-dependent[^1] physical capital factor inputs[^2] to companies building artificial intelligence training models. Nvidia's customer pool is diverse, including tech giants like Google, Microsoft, Amazon, and Facebook, as well as cloud service providers such as AWS, Google Cloud, and Microsoft Azure. Additionally, Nvidia serves self-driving vehicle companies like Tesla and Waymo, healthcare and biotech firms such as Recursion Pharmaceuticals, and financial institutions including JPMorgan Chase.

Moreover, Nvidia's clientele extends to natural language processing (NLP) companies, AI research labs, and chip startups like OpenAI, Anthropic, DeepMind, and Scale AI. The company also caters to entertainment and gaming graphics companies, such as Midjourney. Beyond these, Nvidia supports a wide array of technology startups including the 19,000 recipients of the Nvidia Inception grant.

It is important to note that the above listed pool does not include the millions of retail users (gamers, developers, and performance hardware owners) and the Web 3.0[^3] users (blockchain miners and dApp builders) because they are not directly involved in the artificial intelligence sector. Nevertheless, the artificial intelligence sector is large. How can a new economy industry sector like artificial intelligence become so big so fast?[^4] And, more importantly, what is its economic consequence?

# Economic analysis of artificial intelligence firms

The analysis of artificial intelligence companies is not only to look at how efficiently does the capital investments in factor inputs yield economic profits but also to tabulate all externalities of such capital investments. And, on the topic of capital investments, the role of large players differ than the smaller startups. For one, large corporations' capital investments in artificial intelligence is risk-shared with other prospects in their investment opportunity set. Second, large corporations have existing commitments to abide by various climate pledges made to shareholders. Third, in the event that large corporations plan to relax their commitments towards offsetting carbon footprint, they may cause higher externality effects than the smaller players. Smaller artificial intelligence startups, on the other hand, are exposed to an increased default risk[^5] due to high capital investments need and a lack of a product variety[^6].

## Economic costs

What are the cost to artificial intelligence capital investment?

### Energy

<p align="center">
  <br>
  <img src="assets/img/Dell_servers_nvidia.jpg" alt="Dell servers with Nvidia">
  <em>Dell AI factory with @nvidia to power @grok for @xai @elonmusk <a href="https://x.com/MichaelDell/status/1803385185984974941">tweet</a></em>
</p>

Current artificial intelligence training processes, with their substantial modelling complexities, can result in significant carbon emissions, contingent upon the energy sources employed. This complexity is anticipated to increase exponentially over the next decade. In response, some companies are transitioning to renewable energy sources for their data centers to mitigate the environmental impact. However, these renewable resources were originally designated for existing residential and commercial consumption to aid in reducing our overall carbon footprint and achieving targeted carbon emission reductions. This shift occurs at a time when global electricity demand is projected to escalate rapidly, with an expected annual growth rate of 3.4 percent through 2026.[^7] This shift occurs at a time when fossil fuel-based technologies are facing severe condemnation from governments worldwide.[^8] Let's assume that the costs to maintain carbon neutrality be `A`.

### Water

<p align="center">
  <br>
  <img src="assets/img/datacenters_nvidia.png" alt="Amazon AWS Liquid Cooled Data Center">
  <em>Amazon AWS Liquid Cooled Data Center</em>
</p>

Legacy data centers used for AI require substantial cooling, often using water-based systems. These systems rely on local water reservoirs that are otherwise use for farming, livestock, and human consumption. In 2021, a Google data center consumes 4.3 billion gallons of water annually.[^9] Microsoft's water consumption was nearly 1.7 billion gallons of water in 2022.[^10] Amazon AWS data centers have consumed in excess of a billion gallons of water per year and are expected to become Water-positive only by the year 2030.[^11] This can strain local water resources, especially in water-scarce regions. World Resources Institute reports that, in the next decade, 25 countries, housing one-quarter of the global population, face extremely high water stress, and we can expect these populace to migrate to regions with water. About 70 trillion US dollars in GDP (31 percent of global GDP) will be exposed to high water stress by 2050. Let's assume that the costs to maintain water neutrality be `B`.

### E-waste

The rapid advancement of the artificial intelligence systems necessitates frequent hardware upgrades. As evidenced by Nvidia's own technology conferences, the 2022 chipsets became outdated by 2023, the 2023 chipsets by 2024, and one could expect this pattern to persist into the next decade. Consequently, much of this obsolete electronic waste ends up in landfills and oceans. Let's assume that the costs to maintain e-waste neutrality be `C`.

### Regulation

Regulators have thus far applied generalized technology laws to artificial intelligence products. However, it is becoming increasingly evident that requirements for transparency, consent, and racial/gender inclusion will not be sufficient to ensure artificial intelligence aligns as a social product. A more comprehensive approach is needed to establish artificial intelligence as a public good, incorporating robust antitrust and competition laws. For instance, in July 2024, Nvidia faced antitrust complaints from France, citing anticompetitive practices, over-reliance on CUDA software, and barrier to new entrants. Let's assume that the regulatory costs to be `D`.

Sooner or later, artificial intelligence startups and technology companies are going to weigh in the economic cost against the perceived gains of housing their own artificial intelligence training models, and as costs (`A+B+C+D`) rise, the marginal product on the artificial intelligence capital investments would decline. More empirical work is required to estimate the magnitude of the economic costs of artificial intelligence training. However, one thing is certain: when the true cost estimates of artificial intelligence training (i.e., `A + B + C + D`) are revealed, smaller companies will need to reevaluate the viability of training custom models. They will have to determine whether it is more cost-effective to train their own models or to utilize pre-trained models from large technology companies for a subscription fee.

## What do Nvidia's financials say?

Nvidia's price-to-sales (P/S) ratio is approximately 38, resulting in a revenue per share of `3.23`. In other words, Nvidia, with a market capitalization of around 3 trillion US dollars, generates annual revenue just shy of 80 billion US dollars. For comparison, other companies with similar annual revenues with substantial higher per-share revenues include:

- [Lowe's Companies](https://finance.yahoo.com/quote/LOW/key-statistics/): revenue per share of `150`
- [Albertsons Companies](https://finance.yahoo.com/quote/ACI/key-statistics/): revenue per share of `138`
- [Boeing](https://finance.yahoo.com/quote/BA/key-statistics/): revenue per share of `126`
- [Siemens](https://finance.yahoo.com/quote/SIE.DE/key-statistics/): revenue per share of `100`
- [T-Mobile](https://finance.yahoo.com/quote/TMUS/key-statistics/): revenue per share of `67`
- [Procter & Gamble](https://finance.yahoo.com/quote/PG/key-statistics/): revenue per share of `36`
- [Wells Fargo](https://finance.yahoo.com/quote/WFC/key-statistics/): revenue per share of `21.5`

Nvidia's price-to-earnings (P/E) ratio currently stands at `72`. This means investors are willing to pay 72 dollars for every one dollar of earnings the company generates. In other words, investors would need to wait through 72 earnings cycles (72 quarters, or 18 years) to recoup their investment at the current earnings levels. However, the investor's bet is on potential stock appreciation to mitigate this wait-time. To reduce the wait-time to a typical retail investor's holding period of 36 months, the stock would need to appreciate sixfold. This raises the question: Can Nvidia achieve a sixfold increase from here? This would result in an 18 trillion US dollar market capitalization, which is approximately equivalent to China's current annual output, about 20 percent of the entire world's current annual output, equivalent to the US annual real consumption, or the combined annual outputs of Germany, Japan, India, the UK, and France put together. By all reasonable metrics, such an appreciation appears highly unrealistic. So, why are investors purchasing Nvidia stock at such a high premium, and why do analysts continue to recommend it as a BUY? In essence, it is because they do not fully comprehend the artificial intelligence landscape and are swayed by buzzwords.

Nvidia's risk-return sensitivity, represented by its Beta (5-year average), is `1.69`. This means that a one percent increase (or decrease) in the S&P 500 index return typically associated with a 1.69 percent increase (or decrease) in Nvidia's return. While this high Beta can be advantageous during market expansions, it poses significant risks during market contractions. Some experts predict a severe correction in the US stock market, potentially declining by as much as 40 percent. Given Nvidia's Beta, such a correction would imply a corresponding drop in Nvidia's stock price by approximately 68 percent.

## Remarks

It is quite possible that artificial intelligence startups and technology companies will come to realize the substantial economic costs associated with training models, especially when factoring in the immense social and environmental impacts. When this occurs, the artificial intelligence sector is likely to undergo consolidation, leading to a decline in the demand for physical capital inputs. Consequently, Nvidia's market will contract. Given the high investor expectations for Nvidia's stock appreciation, a reduction in Nvidia's customer base will trigger a correction towards fundamental values. This adjustment will likely bring the stock price back to a level where the price-to-earnings ratio aligns with market peer averages, estimated around `35`.

***

## References

[^1]: Energy, Water, and Land for waste disposal.
[^2]: GPUs (Graphics Processing Units), DGX Systems, HGX Platforms, CUDA, TensorRT SDK, and assorted NVIDIA AI Software and Networking Products.
[^3]: Web 3.0, also known as Web3, refers to the next generation of the internet, which emphasizes decentralization, user control, and improved data privacy and security, using blockchain technologies, cryptocurrencies, and decentralized applications (dApps).
[^4]: One-fourth of all global startup investments, roughly about 25 billion US dollars in 2023, went to the artificial intelligence sector startups, increasing the overall global artificial intelligence market to about 142.3 billion US dollars. AI's anticipated market value by 2025 is 200 billion US dollars. 22 percent of publicly traded firms are aggressively pursuing the integration of AI across a wide variety of technology products.
[^5]: Roughly 90 percent of startup ventures end in failure. In the artificial intelligence sector, only about 20 percent, 25 percent, 40 percent, and 50 percent of startups succeed in the eCommerce and Healthcare, FinTech, EduTech, and gaming industries, respectively.
[^6]: LLMs are unlikely to be one size fits all. Most artificial intelligence products built on today's large language models offer similar retail experiences for customers.
[^7]: See [https://www.iea.org/reports/electricity-2024/executive-summary](https://www.iea.org/reports/electricity-2024/executive-summary)
[^8]: For example, Bitcoin mining.
[^9]: See [https://blog.google/outreach-initiatives/sustainability/our-commitment-to-climate-conscious-data-center-cooling/](https://blog.google/outreach-initiatives/sustainability/our-commitment-to-climate-conscious-data-center-cooling/)
[^10]: See [https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW15mgm](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RW15mgm)
[^11]: See [https://sustainability.aboutamazon.com/natural-resources/water](https://sustainability.aboutamazon.com/natural-resources/water)